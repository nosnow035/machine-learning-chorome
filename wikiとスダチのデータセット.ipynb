{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KA-bYyl1JoN",
        "outputId": "80100948-ae93-493b-9e83-58588fd3a316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sudachipy in /usr/local/lib/python3.12/dist-packages (0.6.10)\n",
            "Requirement already satisfied: sudachidict_core in /usr/local/lib/python3.12/dist-packages (20250825)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.12/dist-packages (0.4.0)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "\n",
            "--- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆé–‹å§‹ ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|â–Œ         | 100/2000 [00:28<03:57,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 100ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|â–‰         | 196/2000 [00:54<06:52,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 200ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|â–ˆâ–        | 295/2000 [01:25<06:38,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 300ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|â–ˆâ–‰        | 399/2000 [01:55<11:59,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 400ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|â–ˆâ–ˆâ–       | 494/2000 [02:16<05:38,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 500ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|â–ˆâ–ˆâ–‰       | 598/2000 [02:41<03:39,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 600ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 696/2000 [04:21<19:44,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 700ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 799/2000 [04:48<04:25,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 800ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 899/2000 [05:16<08:09,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 900ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1000/2000 [05:48<04:06,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1000ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1100/2000 [06:16<04:51,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1100ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1199/2000 [06:45<03:10,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1200ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1296/2000 [07:18<04:26,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1300ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1398/2000 [07:44<02:43,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1400ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1500/2000 [08:08<01:41,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1500ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1598/2000 [08:35<01:34,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1600ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1688/2000 [08:56<01:15,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1700ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1799/2000 [09:25<01:12,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1800ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1900/2000 [09:51<00:35,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 1900ä»¶ã¾ã§ä¿å­˜å®Œäº†\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [10:23<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ 2000ä»¶ã¾ã§ä¿å­˜å®Œäº†\n",
            "\n",
            "âœ… å®Œäº†ï¼ åˆè¨ˆ 2000 æ–‡ã‚’ /content/drive/MyDrive/ãã‚Œã„ãªãƒ†ã‚™ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/wikipedia_datakirei6.csv ã«ä¿å­˜ã—ã¾ã—ãŸã€‚\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# ğŸš€ é«˜ç²¾åº¦ç‰ˆï¼šè¨˜å·ä¿æŒãƒ»èª¤å¤‰æ›ã€Œãã”ã†ã€å®Œå…¨é˜²æ­¢\n",
        "# ==========================================\n",
        "\n",
        "!pip install sudachipy sudachidict_core jaconv wikipedia tqdm\n",
        "\n",
        "import csv\n",
        "import re\n",
        "import time\n",
        "import wikipedia\n",
        "from jaconv import kata2hira\n",
        "from sudachipy import dictionary, tokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ------------------------------------------\n",
        "# ğŸ”§ SudachiPy åˆæœŸåŒ–\n",
        "# ------------------------------------------\n",
        "tokenizer_obj = dictionary.Dictionary().create()\n",
        "mode = tokenizer.Tokenizer.SplitMode.C\n",
        "\n",
        "# ------------------------------------------\n",
        "# ğŸ§¹ ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢\n",
        "# ------------------------------------------\n",
        "def clean_text(text: str) -> str:\n",
        "    return text.replace(\"\\n\", \"\").strip()\n",
        "\n",
        "# ------------------------------------------\n",
        "# ğŸˆ ãµã‚ŠãŒãªç”Ÿæˆï¼ˆè¨˜å·ãƒ»å¤–å›½èªä¿æŒï¼èª¤å¤‰æ›é˜²æ­¢ï¼‰\n",
        "# ------------------------------------------\n",
        "def get_furigana(text: str) -> str:\n",
        "    \"\"\"\n",
        "    - æ¼¢å­—ã ã‘ã²ã‚‰ãŒãªåŒ–\n",
        "    - ã‚«ã‚¿ã‚«ãƒŠã€è‹±æ•°å­—ã€è¨˜å·ã€å¤–å›½èªã¯ãã®ã¾ã¾ä¿æŒ\n",
        "    - ã€Œãã”ã†ã€ãªã©ã®èª¤å‡ºåŠ›ã‚’å®Œå…¨é˜²æ­¢\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for m in tokenizer_obj.tokenize(text, mode):\n",
        "        surface = m.surface()\n",
        "        reading = m.reading_form()\n",
        "\n",
        "        # --- è‹±æ•°å­—ãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»ã‚­ãƒªãƒ«ãƒ»è¨˜å· â†’ ãã®ã¾ã¾ä¿æŒ ---\n",
        "        if re.fullmatch(r\"[A-Za-z0-9Ğ-Ğ¯Ğ°-ÑĞÑ‘Ğ†Ñ–Ğ‡Ñ—Ğ„Ñ”ÒÒ‘ã‚¡-ãƒ´ãƒ¼ãƒ»ãƒ¼ï¼Ã—Ã·ï¼‹âˆ’Â±ï¼…Â°â„ƒÂ§ã€ã€ã€Œã€ã€ã€‘ï¼ˆï¼‰()ï¼»ï¼½ï½›ï½ã€”ã€•ã€ˆã€‰ã€Šã€‹â€œâ€â€˜â€™ãƒ»â€¦â€¥ã€ã€‚ï¼ï¼Ÿï¼šï¼›â€”ã€œãƒ¼ï¼\\-\\[\\]{}<>#@\\$%^&*_+=|\\\\'\\\"~`ï¼ï¼Ÿã€€ã€‚ã€\\s]+\", surface):\n",
        "            result.append(surface)\n",
        "            continue\n",
        "\n",
        "        # --- ã€Œæ¼¢å­—ã‚’å«ã‚€èªã€ã ã‘ã²ã‚‰ãŒãªå¤‰æ› ---\n",
        "        if re.search(r\"[ä¸€-é¾¯]\", surface) and reading and reading != surface:\n",
        "            hira = kata2hira(reading)\n",
        "            result.append(hira)\n",
        "        else:\n",
        "            # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æœªçŸ¥èªãƒ»è¨˜å· â†’ ãã®ã¾ã¾\n",
        "            result.append(surface)\n",
        "\n",
        "    return \"\".join(result)\n",
        "\n",
        "# ------------------------------------------\n",
        "# âš™ï¸ è¨­å®š\n",
        "# ------------------------------------------\n",
        "wikipedia.set_lang(\"ja\")\n",
        "\n",
        "TARGET_COUNT = 2000\n",
        "SAVE_INTERVAL = 100\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/ãã‚Œã„ãªãƒ†ã‚™ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/wikipedia_datakirei6.csv\"\n",
        "SLEEP_TIME = 0.05\n",
        "MIN_SENT_LEN = 5\n",
        "MAX_SENT_LEN = 300\n",
        "\n",
        "# ------------------------------------------\n",
        "# ğŸš§ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ\n",
        "# ------------------------------------------\n",
        "def main():\n",
        "    collected = 0\n",
        "    buffer = []\n",
        "\n",
        "    with open(OUTPUT_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"kanji_sentence\", \"hiragana_sentence\"])\n",
        "\n",
        "    print(f\"\\n--- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆé–‹å§‹ ---\")\n",
        "    pbar = tqdm(total=TARGET_COUNT)\n",
        "\n",
        "    while collected < TARGET_COUNT:\n",
        "        try:\n",
        "            title = wikipedia.random()\n",
        "            page = wikipedia.page(title)\n",
        "            text = clean_text(page.summary)\n",
        "\n",
        "            if not text:\n",
        "                continue\n",
        "\n",
        "            sentences = [s.strip() for s in text.split(\"ã€‚\") if s.strip()]\n",
        "            for s in sentences:\n",
        "                if len(s) < MIN_SENT_LEN or len(s) > MAX_SENT_LEN:\n",
        "                    continue\n",
        "\n",
        "                kanji_sentence = s + \"ã€‚\"\n",
        "                hira_sentence = get_furigana(kanji_sentence)\n",
        "\n",
        "                if hira_sentence == kanji_sentence:\n",
        "                    continue\n",
        "\n",
        "                buffer.append([kanji_sentence, hira_sentence])\n",
        "                collected += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "                if len(buffer) >= SAVE_INTERVAL:\n",
        "                    with open(OUTPUT_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "                        writer = csv.writer(f)\n",
        "                        writer.writerows(buffer)\n",
        "                    buffer.clear()\n",
        "                    print(f\"ğŸ’¾ {collected}ä»¶ã¾ã§ä¿å­˜å®Œäº†\")\n",
        "\n",
        "                if collected >= TARGET_COUNT:\n",
        "                    break\n",
        "\n",
        "            time.sleep(SLEEP_TIME)\n",
        "\n",
        "        except wikipedia.exceptions.DisambiguationError:\n",
        "            continue\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # æ®‹ã‚Šã‚’ä¿å­˜\n",
        "    if buffer:\n",
        "        with open(OUTPUT_FILE, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerows(buffer)\n",
        "\n",
        "    pbar.close()\n",
        "    print(f\"\\nâœ… å®Œäº†ï¼ åˆè¨ˆ {collected} æ–‡ã‚’ {OUTPUT_FILE} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}